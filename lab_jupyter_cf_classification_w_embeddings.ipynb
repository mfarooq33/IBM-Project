{"cells":[{"cell_type":"markdown","id":"69722d66-a240-4961-a3f3-1917c4443689","metadata":{},"source":["<p style=\"text-align:center\">\n","    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML321ENSkillsNetwork817-2022-01-01\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n","    </a>\n","</p>\n"]},{"cell_type":"markdown","id":"75118b4a-01cb-4743-9af8-b5159af89997","metadata":{},"source":["# **Classification-based Rating Mode Prediction using Embedding Features**\n"]},{"cell_type":"markdown","id":"c9052511-27b6-4e8d-8104-d18977c03d54","metadata":{},"source":["Estimated time needed: **60** minutes\n"]},{"cell_type":"markdown","id":"c63f532b-111a-4665-a13c-2a2a56438643","metadata":{},"source":["In this lab, you have built regression models to predict numerical course ratings using the embedding feature vectors extracted from neural networks. We can also consider the prediction problem as a classification problem as rating only has two categorical values (`Aduit` vs. `Completion`).\n"]},{"cell_type":"markdown","id":"dd927a21-9bfe-4f97-94b3-be423241ef90","metadata":{},"source":["![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/module_4/images/rating_classification.png)\n"]},{"cell_type":"markdown","id":"dde3b3d4-0d5f-40f7-819a-2cc1a4a37b72","metadata":{},"source":["The workflow is very similar to our previous lab. We first extract two embedding matrices out of the neural network, and aggregate them to be a single interaction feature vector as input data `X`.\n","\n","This time, with the interaction label `Y` as categorical rating mode, we can build classification models to approximate the mapping from `X` to `Y`, as shown in the above flowchart.\n"]},{"cell_type":"markdown","id":"4c426e10-db0a-4273-a2a4-3a40e2c8ae3e","metadata":{},"source":["## Objectives\n"]},{"cell_type":"markdown","id":"211ab9b0-1bef-4ddf-b5a0-e647bbbad27c","metadata":{},"source":["After completing this lab you will be able to:\n"]},{"cell_type":"markdown","id":"8700e6ae-cdf1-4ac3-a10a-1e816c0143b3","metadata":{},"source":["* Build classification models to predict rating modes using the combined embedding vectors\n"]},{"cell_type":"markdown","id":"3996c7df-d062-4b68-a3ac-9abb4dbdbcb8","metadata":{},"source":["----\n"]},{"cell_type":"markdown","id":"2f4d4a22-8fc2-47e2-b9db-2af28b717056","metadata":{},"source":["## Prepare and setup lab environment\n"]},{"cell_type":"markdown","id":"e4c37f7c-a8fc-4929-83ea-84fdce077dba","metadata":{},"source":["First install and import required libraries:\n"]},{"cell_type":"code","execution_count":1,"id":"208bb64a-2490-41bc-ac7e-f76dfbb8a7d7","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: scikit-learn==1.0.2 in /home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages (1.0.2)\n","Requirement already satisfied: numpy>=1.14.6 in /home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages (from scikit-learn==1.0.2) (1.26.1)\n","Requirement already satisfied: scipy>=1.1.0 in /home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages (from scikit-learn==1.0.2) (1.11.3)\n","Requirement already satisfied: joblib>=0.11 in /home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages (from scikit-learn==1.0.2) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages (from scikit-learn==1.0.2) (3.2.0)\n"]}],"source":["!pip install scikit-learn==1.0.2"]},{"cell_type":"code","execution_count":3,"id":"6700687e-a2b5-4b76-9489-0e86f1a43a1d","metadata":{},"outputs":[],"source":["# also set a random state\n","rs = 123"]},{"cell_type":"code","execution_count":4,"id":"9f6b58e7-cb5f-43c1-ad03-4866c60a3667","metadata":{},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier"]},{"cell_type":"markdown","id":"df8125e6-f563-4544-a531-c171cd7be3c5","metadata":{},"source":["### Load datasets\n"]},{"cell_type":"code","execution_count":5,"id":"96547152-b2f4-4fe2-ba93-1da48d7ba6a9","metadata":{},"outputs":[],"source":["rating_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/datasets/ratings.csv\"\n","user_emb_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/datasets/user_embeddings.csv\"\n","item_emb_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/datasets/course_embeddings.csv\""]},{"cell_type":"markdown","id":"85238ead-e9e5-44c2-8811-bc0bc41af730","metadata":{},"source":["The first dataset is the rating dataset contains user-item interaction matrix\n"]},{"cell_type":"code","execution_count":6,"id":"5b022d15-0b47-400e-b1ef-07fc200dda48","metadata":{},"outputs":[],"source":["rating_df = pd.read_csv(rating_url)"]},{"cell_type":"code","execution_count":7,"id":"c74995c7-148e-404f-91ec-d517fc262434","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user</th>\n","      <th>item</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1889878</td>\n","      <td>CC0101EN</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1342067</td>\n","      <td>CL0101EN</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1990814</td>\n","      <td>ML0120ENv3</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>380098</td>\n","      <td>BD0211EN</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>779563</td>\n","      <td>DS0101EN</td>\n","      <td>3.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      user        item  rating\n","0  1889878    CC0101EN     3.0\n","1  1342067    CL0101EN     3.0\n","2  1990814  ML0120ENv3     3.0\n","3   380098    BD0211EN     3.0\n","4   779563    DS0101EN     3.0"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["rating_df.head()"]},{"cell_type":"markdown","id":"a2e7bee8-9312-45f0-aebf-4de9197474e6","metadata":{},"source":["As you can see from the above data, the user and item are just ids, let's substitute them with their embedding vectors\n"]},{"cell_type":"code","execution_count":8,"id":"0bbb1b17-fcab-4ffa-8bd7-339ee1cf6909","metadata":{},"outputs":[],"source":["user_emb = pd.read_csv(user_emb_url)\n","item_emb = pd.read_csv(item_emb_url)"]},{"cell_type":"code","execution_count":9,"id":"c6edbf66-13fd-417e-87d6-77590933f8eb","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user</th>\n","      <th>UFeature0</th>\n","      <th>UFeature1</th>\n","      <th>UFeature2</th>\n","      <th>UFeature3</th>\n","      <th>UFeature4</th>\n","      <th>UFeature5</th>\n","      <th>UFeature6</th>\n","      <th>UFeature7</th>\n","      <th>UFeature8</th>\n","      <th>UFeature9</th>\n","      <th>UFeature10</th>\n","      <th>UFeature11</th>\n","      <th>UFeature12</th>\n","      <th>UFeature13</th>\n","      <th>UFeature14</th>\n","      <th>UFeature15</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1889878</td>\n","      <td>0.080721</td>\n","      <td>-0.129561</td>\n","      <td>0.087998</td>\n","      <td>0.030231</td>\n","      <td>0.082691</td>\n","      <td>-0.004176</td>\n","      <td>-0.003480</td>\n","      <td>0.091464</td>\n","      <td>-0.040247</td>\n","      <td>0.018958</td>\n","      <td>-0.153328</td>\n","      <td>-0.090143</td>\n","      <td>0.082830</td>\n","      <td>-0.058721</td>\n","      <td>0.057929</td>\n","      <td>-0.001472</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1342067</td>\n","      <td>0.068047</td>\n","      <td>-0.112781</td>\n","      <td>0.045208</td>\n","      <td>-0.007570</td>\n","      <td>-0.038382</td>\n","      <td>0.068037</td>\n","      <td>0.114949</td>\n","      <td>0.104128</td>\n","      <td>-0.034401</td>\n","      <td>0.004011</td>\n","      <td>0.064832</td>\n","      <td>0.165857</td>\n","      <td>-0.004384</td>\n","      <td>0.053257</td>\n","      <td>0.014308</td>\n","      <td>0.056684</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1990814</td>\n","      <td>0.124623</td>\n","      <td>0.012910</td>\n","      <td>-0.072627</td>\n","      <td>0.049935</td>\n","      <td>0.020158</td>\n","      <td>0.133306</td>\n","      <td>-0.035366</td>\n","      <td>-0.156026</td>\n","      <td>0.039269</td>\n","      <td>0.042195</td>\n","      <td>0.014695</td>\n","      <td>-0.115989</td>\n","      <td>0.031158</td>\n","      <td>0.102021</td>\n","      <td>-0.020601</td>\n","      <td>0.116488</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>380098</td>\n","      <td>-0.034870</td>\n","      <td>0.000715</td>\n","      <td>0.077406</td>\n","      <td>0.070311</td>\n","      <td>-0.043007</td>\n","      <td>-0.035446</td>\n","      <td>0.032846</td>\n","      <td>-0.060944</td>\n","      <td>0.112384</td>\n","      <td>0.002114</td>\n","      <td>0.090660</td>\n","      <td>-0.068545</td>\n","      <td>0.008967</td>\n","      <td>0.063962</td>\n","      <td>0.052347</td>\n","      <td>0.018072</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>779563</td>\n","      <td>0.106414</td>\n","      <td>-0.001887</td>\n","      <td>-0.017211</td>\n","      <td>-0.042277</td>\n","      <td>-0.074953</td>\n","      <td>-0.056732</td>\n","      <td>0.074610</td>\n","      <td>-0.019367</td>\n","      <td>-0.031341</td>\n","      <td>0.064896</td>\n","      <td>-0.048158</td>\n","      <td>-0.047309</td>\n","      <td>-0.007544</td>\n","      <td>0.010474</td>\n","      <td>-0.032287</td>\n","      <td>-0.083983</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      user  UFeature0  UFeature1  UFeature2  UFeature3  UFeature4  UFeature5  \\\n","0  1889878   0.080721  -0.129561   0.087998   0.030231   0.082691  -0.004176   \n","1  1342067   0.068047  -0.112781   0.045208  -0.007570  -0.038382   0.068037   \n","2  1990814   0.124623   0.012910  -0.072627   0.049935   0.020158   0.133306   \n","3   380098  -0.034870   0.000715   0.077406   0.070311  -0.043007  -0.035446   \n","4   779563   0.106414  -0.001887  -0.017211  -0.042277  -0.074953  -0.056732   \n","\n","   UFeature6  UFeature7  UFeature8  UFeature9  UFeature10  UFeature11  \\\n","0  -0.003480   0.091464  -0.040247   0.018958   -0.153328   -0.090143   \n","1   0.114949   0.104128  -0.034401   0.004011    0.064832    0.165857   \n","2  -0.035366  -0.156026   0.039269   0.042195    0.014695   -0.115989   \n","3   0.032846  -0.060944   0.112384   0.002114    0.090660   -0.068545   \n","4   0.074610  -0.019367  -0.031341   0.064896   -0.048158   -0.047309   \n","\n","   UFeature12  UFeature13  UFeature14  UFeature15  \n","0    0.082830   -0.058721    0.057929   -0.001472  \n","1   -0.004384    0.053257    0.014308    0.056684  \n","2    0.031158    0.102021   -0.020601    0.116488  \n","3    0.008967    0.063962    0.052347    0.018072  \n","4   -0.007544    0.010474   -0.032287   -0.083983  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["user_emb.head()"]},{"cell_type":"code","execution_count":10,"id":"4db99089-630d-4717-ae90-4dd758ee37bf","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>item</th>\n","      <th>CFeature0</th>\n","      <th>CFeature1</th>\n","      <th>CFeature2</th>\n","      <th>CFeature3</th>\n","      <th>CFeature4</th>\n","      <th>CFeature5</th>\n","      <th>CFeature6</th>\n","      <th>CFeature7</th>\n","      <th>CFeature8</th>\n","      <th>CFeature9</th>\n","      <th>CFeature10</th>\n","      <th>CFeature11</th>\n","      <th>CFeature12</th>\n","      <th>CFeature13</th>\n","      <th>CFeature14</th>\n","      <th>CFeature15</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>CC0101EN</td>\n","      <td>0.009657</td>\n","      <td>-0.005238</td>\n","      <td>-0.004098</td>\n","      <td>0.016303</td>\n","      <td>-0.005274</td>\n","      <td>-0.000361</td>\n","      <td>-0.015081</td>\n","      <td>-0.012229</td>\n","      <td>0.015686</td>\n","      <td>0.008401</td>\n","      <td>-0.035495</td>\n","      <td>0.009381</td>\n","      <td>-0.032560</td>\n","      <td>-0.007292</td>\n","      <td>0.000966</td>\n","      <td>-0.006218</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CL0101EN</td>\n","      <td>-0.008611</td>\n","      <td>0.028041</td>\n","      <td>0.021899</td>\n","      <td>-0.001465</td>\n","      <td>0.006900</td>\n","      <td>-0.017981</td>\n","      <td>0.010899</td>\n","      <td>-0.037610</td>\n","      <td>-0.019397</td>\n","      <td>-0.025682</td>\n","      <td>-0.000620</td>\n","      <td>0.038803</td>\n","      <td>0.000196</td>\n","      <td>-0.045343</td>\n","      <td>0.012863</td>\n","      <td>0.019429</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ML0120ENv3</td>\n","      <td>0.027439</td>\n","      <td>-0.027649</td>\n","      <td>-0.007484</td>\n","      <td>-0.059451</td>\n","      <td>0.003972</td>\n","      <td>0.020496</td>\n","      <td>-0.012695</td>\n","      <td>0.036138</td>\n","      <td>0.019965</td>\n","      <td>0.018686</td>\n","      <td>-0.010450</td>\n","      <td>-0.050011</td>\n","      <td>0.013845</td>\n","      <td>-0.044454</td>\n","      <td>-0.001480</td>\n","      <td>-0.007559</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>BD0211EN</td>\n","      <td>0.020163</td>\n","      <td>-0.011972</td>\n","      <td>-0.003714</td>\n","      <td>-0.015548</td>\n","      <td>-0.007540</td>\n","      <td>0.014847</td>\n","      <td>-0.005700</td>\n","      <td>-0.006068</td>\n","      <td>-0.005792</td>\n","      <td>-0.023036</td>\n","      <td>0.015999</td>\n","      <td>-0.023480</td>\n","      <td>0.015469</td>\n","      <td>0.022221</td>\n","      <td>-0.023115</td>\n","      <td>-0.001785</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>DS0101EN</td>\n","      <td>0.006399</td>\n","      <td>0.000492</td>\n","      <td>0.005640</td>\n","      <td>0.009639</td>\n","      <td>-0.005487</td>\n","      <td>-0.000590</td>\n","      <td>-0.010015</td>\n","      <td>-0.001514</td>\n","      <td>-0.017598</td>\n","      <td>0.003590</td>\n","      <td>0.016799</td>\n","      <td>0.002732</td>\n","      <td>0.005162</td>\n","      <td>0.015031</td>\n","      <td>-0.000877</td>\n","      <td>-0.021283</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         item  CFeature0  CFeature1  CFeature2  CFeature3  CFeature4  \\\n","0    CC0101EN   0.009657  -0.005238  -0.004098   0.016303  -0.005274   \n","1    CL0101EN  -0.008611   0.028041   0.021899  -0.001465   0.006900   \n","2  ML0120ENv3   0.027439  -0.027649  -0.007484  -0.059451   0.003972   \n","3    BD0211EN   0.020163  -0.011972  -0.003714  -0.015548  -0.007540   \n","4    DS0101EN   0.006399   0.000492   0.005640   0.009639  -0.005487   \n","\n","   CFeature5  CFeature6  CFeature7  CFeature8  CFeature9  CFeature10  \\\n","0  -0.000361  -0.015081  -0.012229   0.015686   0.008401   -0.035495   \n","1  -0.017981   0.010899  -0.037610  -0.019397  -0.025682   -0.000620   \n","2   0.020496  -0.012695   0.036138   0.019965   0.018686   -0.010450   \n","3   0.014847  -0.005700  -0.006068  -0.005792  -0.023036    0.015999   \n","4  -0.000590  -0.010015  -0.001514  -0.017598   0.003590    0.016799   \n","\n","   CFeature11  CFeature12  CFeature13  CFeature14  CFeature15  \n","0    0.009381   -0.032560   -0.007292    0.000966   -0.006218  \n","1    0.038803    0.000196   -0.045343    0.012863    0.019429  \n","2   -0.050011    0.013845   -0.044454   -0.001480   -0.007559  \n","3   -0.023480    0.015469    0.022221   -0.023115   -0.001785  \n","4    0.002732    0.005162    0.015031   -0.000877   -0.021283  "]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["item_emb.head()"]},{"cell_type":"code","execution_count":11,"id":"22fd3589-c449-4857-ada8-088d40a99f0a","metadata":{},"outputs":[],"source":["# Merge user embedding features\n","merged_df = pd.merge(rating_df, user_emb, how='left', left_on='user', right_on='user').fillna(0)\n","# Merge course embedding features\n","merged_df = pd.merge(merged_df, item_emb, how='left', left_on='item', right_on='item').fillna(0)"]},{"cell_type":"code","execution_count":12,"id":"37e2879f-46c5-4d64-89ab-17fe8d68b81c","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user</th>\n","      <th>item</th>\n","      <th>rating</th>\n","      <th>UFeature0</th>\n","      <th>UFeature1</th>\n","      <th>UFeature2</th>\n","      <th>UFeature3</th>\n","      <th>UFeature4</th>\n","      <th>UFeature5</th>\n","      <th>UFeature6</th>\n","      <th>...</th>\n","      <th>CFeature6</th>\n","      <th>CFeature7</th>\n","      <th>CFeature8</th>\n","      <th>CFeature9</th>\n","      <th>CFeature10</th>\n","      <th>CFeature11</th>\n","      <th>CFeature12</th>\n","      <th>CFeature13</th>\n","      <th>CFeature14</th>\n","      <th>CFeature15</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1889878</td>\n","      <td>CC0101EN</td>\n","      <td>3.0</td>\n","      <td>0.080721</td>\n","      <td>-0.129561</td>\n","      <td>0.087998</td>\n","      <td>0.030231</td>\n","      <td>0.082691</td>\n","      <td>-0.004176</td>\n","      <td>-0.003480</td>\n","      <td>...</td>\n","      <td>-0.015081</td>\n","      <td>-0.012229</td>\n","      <td>0.015686</td>\n","      <td>0.008401</td>\n","      <td>-0.035495</td>\n","      <td>0.009381</td>\n","      <td>-0.032560</td>\n","      <td>-0.007292</td>\n","      <td>0.000966</td>\n","      <td>-0.006218</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1342067</td>\n","      <td>CL0101EN</td>\n","      <td>3.0</td>\n","      <td>0.068047</td>\n","      <td>-0.112781</td>\n","      <td>0.045208</td>\n","      <td>-0.007570</td>\n","      <td>-0.038382</td>\n","      <td>0.068037</td>\n","      <td>0.114949</td>\n","      <td>...</td>\n","      <td>0.010899</td>\n","      <td>-0.037610</td>\n","      <td>-0.019397</td>\n","      <td>-0.025682</td>\n","      <td>-0.000620</td>\n","      <td>0.038803</td>\n","      <td>0.000196</td>\n","      <td>-0.045343</td>\n","      <td>0.012863</td>\n","      <td>0.019429</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1990814</td>\n","      <td>ML0120ENv3</td>\n","      <td>3.0</td>\n","      <td>0.124623</td>\n","      <td>0.012910</td>\n","      <td>-0.072627</td>\n","      <td>0.049935</td>\n","      <td>0.020158</td>\n","      <td>0.133306</td>\n","      <td>-0.035366</td>\n","      <td>...</td>\n","      <td>-0.012695</td>\n","      <td>0.036138</td>\n","      <td>0.019965</td>\n","      <td>0.018686</td>\n","      <td>-0.010450</td>\n","      <td>-0.050011</td>\n","      <td>0.013845</td>\n","      <td>-0.044454</td>\n","      <td>-0.001480</td>\n","      <td>-0.007559</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>380098</td>\n","      <td>BD0211EN</td>\n","      <td>3.0</td>\n","      <td>-0.034870</td>\n","      <td>0.000715</td>\n","      <td>0.077406</td>\n","      <td>0.070311</td>\n","      <td>-0.043007</td>\n","      <td>-0.035446</td>\n","      <td>0.032846</td>\n","      <td>...</td>\n","      <td>-0.005700</td>\n","      <td>-0.006068</td>\n","      <td>-0.005792</td>\n","      <td>-0.023036</td>\n","      <td>0.015999</td>\n","      <td>-0.023480</td>\n","      <td>0.015469</td>\n","      <td>0.022221</td>\n","      <td>-0.023115</td>\n","      <td>-0.001785</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>779563</td>\n","      <td>DS0101EN</td>\n","      <td>3.0</td>\n","      <td>0.106414</td>\n","      <td>-0.001887</td>\n","      <td>-0.017211</td>\n","      <td>-0.042277</td>\n","      <td>-0.074953</td>\n","      <td>-0.056732</td>\n","      <td>0.074610</td>\n","      <td>...</td>\n","      <td>-0.010015</td>\n","      <td>-0.001514</td>\n","      <td>-0.017598</td>\n","      <td>0.003590</td>\n","      <td>0.016799</td>\n","      <td>0.002732</td>\n","      <td>0.005162</td>\n","      <td>0.015031</td>\n","      <td>-0.000877</td>\n","      <td>-0.021283</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 35 columns</p>\n","</div>"],"text/plain":["      user        item  rating  UFeature0  UFeature1  UFeature2  UFeature3  \\\n","0  1889878    CC0101EN     3.0   0.080721  -0.129561   0.087998   0.030231   \n","1  1342067    CL0101EN     3.0   0.068047  -0.112781   0.045208  -0.007570   \n","2  1990814  ML0120ENv3     3.0   0.124623   0.012910  -0.072627   0.049935   \n","3   380098    BD0211EN     3.0  -0.034870   0.000715   0.077406   0.070311   \n","4   779563    DS0101EN     3.0   0.106414  -0.001887  -0.017211  -0.042277   \n","\n","   UFeature4  UFeature5  UFeature6  ...  CFeature6  CFeature7  CFeature8  \\\n","0   0.082691  -0.004176  -0.003480  ...  -0.015081  -0.012229   0.015686   \n","1  -0.038382   0.068037   0.114949  ...   0.010899  -0.037610  -0.019397   \n","2   0.020158   0.133306  -0.035366  ...  -0.012695   0.036138   0.019965   \n","3  -0.043007  -0.035446   0.032846  ...  -0.005700  -0.006068  -0.005792   \n","4  -0.074953  -0.056732   0.074610  ...  -0.010015  -0.001514  -0.017598   \n","\n","   CFeature9  CFeature10  CFeature11  CFeature12  CFeature13  CFeature14  \\\n","0   0.008401   -0.035495    0.009381   -0.032560   -0.007292    0.000966   \n","1  -0.025682   -0.000620    0.038803    0.000196   -0.045343    0.012863   \n","2   0.018686   -0.010450   -0.050011    0.013845   -0.044454   -0.001480   \n","3  -0.023036    0.015999   -0.023480    0.015469    0.022221   -0.023115   \n","4   0.003590    0.016799    0.002732    0.005162    0.015031   -0.000877   \n","\n","   CFeature15  \n","0   -0.006218  \n","1    0.019429  \n","2   -0.007559  \n","3   -0.001785  \n","4   -0.021283  \n","\n","[5 rows x 35 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["merged_df.head()"]},{"cell_type":"markdown","id":"8b3522c3-467f-4b89-a636-0bdac34ad05f","metadata":{},"source":["Each user's embedding features and each item's embedding features are added to the dataset. Next, we perform element-wise add the user features (the column labels starting with `UFeature`) and item features (the column labels starting with `CFeature`).\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["u_feautres = [f\"UFeature{i}\" for i in range(16)]\n","c_features = [f\"CFeature{i}\" for i in range(16)]"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["['UFeature0',\n"," 'UFeature1',\n"," 'UFeature2',\n"," 'UFeature3',\n"," 'UFeature4',\n"," 'UFeature5',\n"," 'UFeature6',\n"," 'UFeature7',\n"," 'UFeature8',\n"," 'UFeature9',\n"," 'UFeature10',\n"," 'UFeature11',\n"," 'UFeature12',\n"," 'UFeature13',\n"," 'UFeature14',\n"," 'UFeature15']"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["u_feautres"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["['CFeature0',\n"," 'CFeature1',\n"," 'CFeature2',\n"," 'CFeature3',\n"," 'CFeature4',\n"," 'CFeature5',\n"," 'CFeature6',\n"," 'CFeature7',\n"," 'CFeature8',\n"," 'CFeature9',\n"," 'CFeature10',\n"," 'CFeature11',\n"," 'CFeature12',\n"," 'CFeature13',\n"," 'CFeature14',\n"," 'CFeature15']"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["c_features"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["user_embeddings = merged_df[u_feautres]\n","course_embeddings = merged_df[c_features]"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>UFeature0</th>\n","      <th>UFeature1</th>\n","      <th>UFeature2</th>\n","      <th>UFeature3</th>\n","      <th>UFeature4</th>\n","      <th>UFeature5</th>\n","      <th>UFeature6</th>\n","      <th>UFeature7</th>\n","      <th>UFeature8</th>\n","      <th>UFeature9</th>\n","      <th>UFeature10</th>\n","      <th>UFeature11</th>\n","      <th>UFeature12</th>\n","      <th>UFeature13</th>\n","      <th>UFeature14</th>\n","      <th>UFeature15</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.080721</td>\n","      <td>-0.129561</td>\n","      <td>0.087998</td>\n","      <td>0.030231</td>\n","      <td>0.082691</td>\n","      <td>-0.004176</td>\n","      <td>-0.003480</td>\n","      <td>0.091464</td>\n","      <td>-0.040247</td>\n","      <td>0.018958</td>\n","      <td>-0.153328</td>\n","      <td>-0.090143</td>\n","      <td>0.082830</td>\n","      <td>-0.058721</td>\n","      <td>0.057929</td>\n","      <td>-0.001472</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.068047</td>\n","      <td>-0.112781</td>\n","      <td>0.045208</td>\n","      <td>-0.007570</td>\n","      <td>-0.038382</td>\n","      <td>0.068037</td>\n","      <td>0.114949</td>\n","      <td>0.104128</td>\n","      <td>-0.034401</td>\n","      <td>0.004011</td>\n","      <td>0.064832</td>\n","      <td>0.165857</td>\n","      <td>-0.004384</td>\n","      <td>0.053257</td>\n","      <td>0.014308</td>\n","      <td>0.056684</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.124623</td>\n","      <td>0.012910</td>\n","      <td>-0.072627</td>\n","      <td>0.049935</td>\n","      <td>0.020158</td>\n","      <td>0.133306</td>\n","      <td>-0.035366</td>\n","      <td>-0.156026</td>\n","      <td>0.039269</td>\n","      <td>0.042195</td>\n","      <td>0.014695</td>\n","      <td>-0.115989</td>\n","      <td>0.031158</td>\n","      <td>0.102021</td>\n","      <td>-0.020601</td>\n","      <td>0.116488</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.034870</td>\n","      <td>0.000715</td>\n","      <td>0.077406</td>\n","      <td>0.070311</td>\n","      <td>-0.043007</td>\n","      <td>-0.035446</td>\n","      <td>0.032846</td>\n","      <td>-0.060944</td>\n","      <td>0.112384</td>\n","      <td>0.002114</td>\n","      <td>0.090660</td>\n","      <td>-0.068545</td>\n","      <td>0.008967</td>\n","      <td>0.063962</td>\n","      <td>0.052347</td>\n","      <td>0.018072</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.106414</td>\n","      <td>-0.001887</td>\n","      <td>-0.017211</td>\n","      <td>-0.042277</td>\n","      <td>-0.074953</td>\n","      <td>-0.056732</td>\n","      <td>0.074610</td>\n","      <td>-0.019367</td>\n","      <td>-0.031341</td>\n","      <td>0.064896</td>\n","      <td>-0.048158</td>\n","      <td>-0.047309</td>\n","      <td>-0.007544</td>\n","      <td>0.010474</td>\n","      <td>-0.032287</td>\n","      <td>-0.083983</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.023796</td>\n","      <td>0.063062</td>\n","      <td>0.111711</td>\n","      <td>0.008723</td>\n","      <td>0.083231</td>\n","      <td>0.095042</td>\n","      <td>0.026420</td>\n","      <td>-0.014873</td>\n","      <td>-0.028716</td>\n","      <td>0.042140</td>\n","      <td>-0.012092</td>\n","      <td>0.081946</td>\n","      <td>0.006987</td>\n","      <td>-0.073148</td>\n","      <td>0.044278</td>\n","      <td>0.044275</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>-0.058648</td>\n","      <td>-0.089343</td>\n","      <td>0.121690</td>\n","      <td>0.019357</td>\n","      <td>-0.037281</td>\n","      <td>0.049743</td>\n","      <td>0.063332</td>\n","      <td>0.045058</td>\n","      <td>-0.006939</td>\n","      <td>-0.009103</td>\n","      <td>-0.211956</td>\n","      <td>-0.050017</td>\n","      <td>-0.158781</td>\n","      <td>0.031542</td>\n","      <td>0.037287</td>\n","      <td>-0.041091</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.021692</td>\n","      <td>-0.010020</td>\n","      <td>-0.033231</td>\n","      <td>-0.065473</td>\n","      <td>0.032229</td>\n","      <td>-0.019532</td>\n","      <td>0.023956</td>\n","      <td>-0.047255</td>\n","      <td>-0.028421</td>\n","      <td>0.027716</td>\n","      <td>0.081974</td>\n","      <td>-0.059678</td>\n","      <td>0.076866</td>\n","      <td>-0.101812</td>\n","      <td>-0.002822</td>\n","      <td>0.049491</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>-0.037679</td>\n","      <td>-0.051901</td>\n","      <td>0.011822</td>\n","      <td>-0.027294</td>\n","      <td>0.020662</td>\n","      <td>-0.033249</td>\n","      <td>-0.048535</td>\n","      <td>0.023609</td>\n","      <td>0.000347</td>\n","      <td>0.089887</td>\n","      <td>0.024953</td>\n","      <td>-0.091012</td>\n","      <td>-0.140504</td>\n","      <td>0.018190</td>\n","      <td>0.035233</td>\n","      <td>0.011054</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.050706</td>\n","      <td>0.092145</td>\n","      <td>0.004021</td>\n","      <td>0.046852</td>\n","      <td>0.088993</td>\n","      <td>0.095863</td>\n","      <td>0.022414</td>\n","      <td>-0.093847</td>\n","      <td>-0.061130</td>\n","      <td>-0.014215</td>\n","      <td>-0.028370</td>\n","      <td>-0.017722</td>\n","      <td>-0.013436</td>\n","      <td>0.063654</td>\n","      <td>-0.010560</td>\n","      <td>0.114723</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   UFeature0  UFeature1  UFeature2  UFeature3  UFeature4  UFeature5  \\\n","0   0.080721  -0.129561   0.087998   0.030231   0.082691  -0.004176   \n","1   0.068047  -0.112781   0.045208  -0.007570  -0.038382   0.068037   \n","2   0.124623   0.012910  -0.072627   0.049935   0.020158   0.133306   \n","3  -0.034870   0.000715   0.077406   0.070311  -0.043007  -0.035446   \n","4   0.106414  -0.001887  -0.017211  -0.042277  -0.074953  -0.056732   \n","5   0.023796   0.063062   0.111711   0.008723   0.083231   0.095042   \n","6  -0.058648  -0.089343   0.121690   0.019357  -0.037281   0.049743   \n","7   0.021692  -0.010020  -0.033231  -0.065473   0.032229  -0.019532   \n","8  -0.037679  -0.051901   0.011822  -0.027294   0.020662  -0.033249   \n","9   0.050706   0.092145   0.004021   0.046852   0.088993   0.095863   \n","\n","   UFeature6  UFeature7  UFeature8  UFeature9  UFeature10  UFeature11  \\\n","0  -0.003480   0.091464  -0.040247   0.018958   -0.153328   -0.090143   \n","1   0.114949   0.104128  -0.034401   0.004011    0.064832    0.165857   \n","2  -0.035366  -0.156026   0.039269   0.042195    0.014695   -0.115989   \n","3   0.032846  -0.060944   0.112384   0.002114    0.090660   -0.068545   \n","4   0.074610  -0.019367  -0.031341   0.064896   -0.048158   -0.047309   \n","5   0.026420  -0.014873  -0.028716   0.042140   -0.012092    0.081946   \n","6   0.063332   0.045058  -0.006939  -0.009103   -0.211956   -0.050017   \n","7   0.023956  -0.047255  -0.028421   0.027716    0.081974   -0.059678   \n","8  -0.048535   0.023609   0.000347   0.089887    0.024953   -0.091012   \n","9   0.022414  -0.093847  -0.061130  -0.014215   -0.028370   -0.017722   \n","\n","   UFeature12  UFeature13  UFeature14  UFeature15  \n","0    0.082830   -0.058721    0.057929   -0.001472  \n","1   -0.004384    0.053257    0.014308    0.056684  \n","2    0.031158    0.102021   -0.020601    0.116488  \n","3    0.008967    0.063962    0.052347    0.018072  \n","4   -0.007544    0.010474   -0.032287   -0.083983  \n","5    0.006987   -0.073148    0.044278    0.044275  \n","6   -0.158781    0.031542    0.037287   -0.041091  \n","7    0.076866   -0.101812   -0.002822    0.049491  \n","8   -0.140504    0.018190    0.035233    0.011054  \n","9   -0.013436    0.063654   -0.010560    0.114723  "]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["user_embeddings.head(10)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CFeature0</th>\n","      <th>CFeature1</th>\n","      <th>CFeature2</th>\n","      <th>CFeature3</th>\n","      <th>CFeature4</th>\n","      <th>CFeature5</th>\n","      <th>CFeature6</th>\n","      <th>CFeature7</th>\n","      <th>CFeature8</th>\n","      <th>CFeature9</th>\n","      <th>CFeature10</th>\n","      <th>CFeature11</th>\n","      <th>CFeature12</th>\n","      <th>CFeature13</th>\n","      <th>CFeature14</th>\n","      <th>CFeature15</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.009657</td>\n","      <td>-0.005238</td>\n","      <td>-0.004098</td>\n","      <td>0.016303</td>\n","      <td>-0.005274</td>\n","      <td>-0.000361</td>\n","      <td>-0.015081</td>\n","      <td>-0.012229</td>\n","      <td>0.015686</td>\n","      <td>0.008401</td>\n","      <td>-0.035495</td>\n","      <td>0.009381</td>\n","      <td>-0.032560</td>\n","      <td>-0.007292</td>\n","      <td>0.000966</td>\n","      <td>-0.006218</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.008611</td>\n","      <td>0.028041</td>\n","      <td>0.021899</td>\n","      <td>-0.001465</td>\n","      <td>0.006900</td>\n","      <td>-0.017981</td>\n","      <td>0.010899</td>\n","      <td>-0.037610</td>\n","      <td>-0.019397</td>\n","      <td>-0.025682</td>\n","      <td>-0.000620</td>\n","      <td>0.038803</td>\n","      <td>0.000196</td>\n","      <td>-0.045343</td>\n","      <td>0.012863</td>\n","      <td>0.019429</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.027439</td>\n","      <td>-0.027649</td>\n","      <td>-0.007484</td>\n","      <td>-0.059451</td>\n","      <td>0.003972</td>\n","      <td>0.020496</td>\n","      <td>-0.012695</td>\n","      <td>0.036138</td>\n","      <td>0.019965</td>\n","      <td>0.018686</td>\n","      <td>-0.010450</td>\n","      <td>-0.050011</td>\n","      <td>0.013845</td>\n","      <td>-0.044454</td>\n","      <td>-0.001480</td>\n","      <td>-0.007559</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.020163</td>\n","      <td>-0.011972</td>\n","      <td>-0.003714</td>\n","      <td>-0.015548</td>\n","      <td>-0.007540</td>\n","      <td>0.014847</td>\n","      <td>-0.005700</td>\n","      <td>-0.006068</td>\n","      <td>-0.005792</td>\n","      <td>-0.023036</td>\n","      <td>0.015999</td>\n","      <td>-0.023480</td>\n","      <td>0.015469</td>\n","      <td>0.022221</td>\n","      <td>-0.023115</td>\n","      <td>-0.001785</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.006399</td>\n","      <td>0.000492</td>\n","      <td>0.005640</td>\n","      <td>0.009639</td>\n","      <td>-0.005487</td>\n","      <td>-0.000590</td>\n","      <td>-0.010015</td>\n","      <td>-0.001514</td>\n","      <td>-0.017598</td>\n","      <td>0.003590</td>\n","      <td>0.016799</td>\n","      <td>0.002732</td>\n","      <td>0.005162</td>\n","      <td>0.015031</td>\n","      <td>-0.000877</td>\n","      <td>-0.021283</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   CFeature0  CFeature1  CFeature2  CFeature3  CFeature4  CFeature5  \\\n","0   0.009657  -0.005238  -0.004098   0.016303  -0.005274  -0.000361   \n","1  -0.008611   0.028041   0.021899  -0.001465   0.006900  -0.017981   \n","2   0.027439  -0.027649  -0.007484  -0.059451   0.003972   0.020496   \n","3   0.020163  -0.011972  -0.003714  -0.015548  -0.007540   0.014847   \n","4   0.006399   0.000492   0.005640   0.009639  -0.005487  -0.000590   \n","\n","   CFeature6  CFeature7  CFeature8  CFeature9  CFeature10  CFeature11  \\\n","0  -0.015081  -0.012229   0.015686   0.008401   -0.035495    0.009381   \n","1   0.010899  -0.037610  -0.019397  -0.025682   -0.000620    0.038803   \n","2  -0.012695   0.036138   0.019965   0.018686   -0.010450   -0.050011   \n","3  -0.005700  -0.006068  -0.005792  -0.023036    0.015999   -0.023480   \n","4  -0.010015  -0.001514  -0.017598   0.003590    0.016799    0.002732   \n","\n","   CFeature12  CFeature13  CFeature14  CFeature15  \n","0   -0.032560   -0.007292    0.000966   -0.006218  \n","1    0.000196   -0.045343    0.012863    0.019429  \n","2    0.013845   -0.044454   -0.001480   -0.007559  \n","3    0.015469    0.022221   -0.023115   -0.001785  \n","4    0.005162    0.015031   -0.000877   -0.021283  "]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["course_embeddings.head()"]},{"cell_type":"code","execution_count":22,"id":"c0a886ec-b1e1-4713-9c46-cf4481831326","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Feature0</th>\n","      <th>Feature1</th>\n","      <th>Feature2</th>\n","      <th>Feature3</th>\n","      <th>Feature4</th>\n","      <th>Feature5</th>\n","      <th>Feature6</th>\n","      <th>Feature7</th>\n","      <th>Feature8</th>\n","      <th>Feature9</th>\n","      <th>Feature10</th>\n","      <th>Feature11</th>\n","      <th>Feature12</th>\n","      <th>Feature13</th>\n","      <th>Feature14</th>\n","      <th>Feature15</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.090378</td>\n","      <td>-0.134799</td>\n","      <td>0.083900</td>\n","      <td>0.046534</td>\n","      <td>0.077417</td>\n","      <td>-0.004537</td>\n","      <td>-0.018561</td>\n","      <td>0.079236</td>\n","      <td>-0.024561</td>\n","      <td>0.027359</td>\n","      <td>-0.188823</td>\n","      <td>-0.080762</td>\n","      <td>0.050271</td>\n","      <td>-0.066013</td>\n","      <td>0.058894</td>\n","      <td>-0.007689</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.059437</td>\n","      <td>-0.084740</td>\n","      <td>0.067107</td>\n","      <td>-0.009036</td>\n","      <td>-0.031482</td>\n","      <td>0.050057</td>\n","      <td>0.125847</td>\n","      <td>0.066517</td>\n","      <td>-0.053798</td>\n","      <td>-0.021671</td>\n","      <td>0.064212</td>\n","      <td>0.204660</td>\n","      <td>-0.004188</td>\n","      <td>0.007914</td>\n","      <td>0.027170</td>\n","      <td>0.076114</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.152061</td>\n","      <td>-0.014739</td>\n","      <td>-0.080112</td>\n","      <td>-0.009516</td>\n","      <td>0.024130</td>\n","      <td>0.153802</td>\n","      <td>-0.048061</td>\n","      <td>-0.119888</td>\n","      <td>0.059234</td>\n","      <td>0.060882</td>\n","      <td>0.004244</td>\n","      <td>-0.166000</td>\n","      <td>0.045002</td>\n","      <td>0.057566</td>\n","      <td>-0.022081</td>\n","      <td>0.108929</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.014707</td>\n","      <td>-0.011257</td>\n","      <td>0.073692</td>\n","      <td>0.054763</td>\n","      <td>-0.050547</td>\n","      <td>-0.020599</td>\n","      <td>0.027146</td>\n","      <td>-0.067012</td>\n","      <td>0.106593</td>\n","      <td>-0.020921</td>\n","      <td>0.106658</td>\n","      <td>-0.092025</td>\n","      <td>0.024436</td>\n","      <td>0.086183</td>\n","      <td>0.029232</td>\n","      <td>0.016287</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.112812</td>\n","      <td>-0.001395</td>\n","      <td>-0.011572</td>\n","      <td>-0.032638</td>\n","      <td>-0.080440</td>\n","      <td>-0.057321</td>\n","      <td>0.064595</td>\n","      <td>-0.020880</td>\n","      <td>-0.048939</td>\n","      <td>0.068486</td>\n","      <td>-0.031359</td>\n","      <td>-0.044577</td>\n","      <td>-0.002381</td>\n","      <td>0.025505</td>\n","      <td>-0.033164</td>\n","      <td>-0.105266</td>\n","      <td>3.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Feature0  Feature1  Feature2  Feature3  Feature4  Feature5  Feature6  \\\n","0  0.090378 -0.134799  0.083900  0.046534  0.077417 -0.004537 -0.018561   \n","1  0.059437 -0.084740  0.067107 -0.009036 -0.031482  0.050057  0.125847   \n","2  0.152061 -0.014739 -0.080112 -0.009516  0.024130  0.153802 -0.048061   \n","3 -0.014707 -0.011257  0.073692  0.054763 -0.050547 -0.020599  0.027146   \n","4  0.112812 -0.001395 -0.011572 -0.032638 -0.080440 -0.057321  0.064595   \n","\n","   Feature7  Feature8  Feature9  Feature10  Feature11  Feature12  Feature13  \\\n","0  0.079236 -0.024561  0.027359  -0.188823  -0.080762   0.050271  -0.066013   \n","1  0.066517 -0.053798 -0.021671   0.064212   0.204660  -0.004188   0.007914   \n","2 -0.119888  0.059234  0.060882   0.004244  -0.166000   0.045002   0.057566   \n","3 -0.067012  0.106593 -0.020921   0.106658  -0.092025   0.024436   0.086183   \n","4 -0.020880 -0.048939  0.068486  -0.031359  -0.044577  -0.002381   0.025505   \n","\n","   Feature14  Feature15  rating  \n","0   0.058894  -0.007689     3.0  \n","1   0.027170   0.076114     3.0  \n","2  -0.022081   0.108929     3.0  \n","3   0.029232   0.016287     3.0  \n","4  -0.033164  -0.105266     3.0  "]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["ratings = merged_df['rating']\n","\n","# Aggregate the two feature columns using element-wise add\n","interaction_dataset = user_embeddings + course_embeddings.values\n","interaction_dataset.columns = [f\"Feature{i}\" for i in range(16)]\n","interaction_dataset['rating'] = ratings\n","interaction_dataset.head()"]},{"cell_type":"markdown","id":"92d57a6e-65f8-48c3-9bf2-fda9f235630d","metadata":{},"source":["Next, let's use `LabelEncoder()` to encode our `rating` label to be categorical:\n"]},{"cell_type":"code","execution_count":23,"id":"805bf0fa-4689-41e6-bc14-5382e6f5b619","metadata":{},"outputs":[],"source":["X = interaction_dataset.iloc[:, :-1]\n","y_raw = interaction_dataset.iloc[:, -1]\n","\n","label_encoder = LabelEncoder()\n","y = label_encoder.fit_transform(y_raw.values.ravel())"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Feature0</th>\n","      <th>Feature1</th>\n","      <th>Feature2</th>\n","      <th>Feature3</th>\n","      <th>Feature4</th>\n","      <th>Feature5</th>\n","      <th>Feature6</th>\n","      <th>Feature7</th>\n","      <th>Feature8</th>\n","      <th>Feature9</th>\n","      <th>Feature10</th>\n","      <th>Feature11</th>\n","      <th>Feature12</th>\n","      <th>Feature13</th>\n","      <th>Feature14</th>\n","      <th>Feature15</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.090378</td>\n","      <td>-0.134799</td>\n","      <td>0.083900</td>\n","      <td>0.046534</td>\n","      <td>0.077417</td>\n","      <td>-0.004537</td>\n","      <td>-0.018561</td>\n","      <td>0.079236</td>\n","      <td>-0.024561</td>\n","      <td>0.027359</td>\n","      <td>-0.188823</td>\n","      <td>-0.080762</td>\n","      <td>0.050271</td>\n","      <td>-0.066013</td>\n","      <td>0.058894</td>\n","      <td>-0.007689</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.059437</td>\n","      <td>-0.084740</td>\n","      <td>0.067107</td>\n","      <td>-0.009036</td>\n","      <td>-0.031482</td>\n","      <td>0.050057</td>\n","      <td>0.125847</td>\n","      <td>0.066517</td>\n","      <td>-0.053798</td>\n","      <td>-0.021671</td>\n","      <td>0.064212</td>\n","      <td>0.204660</td>\n","      <td>-0.004188</td>\n","      <td>0.007914</td>\n","      <td>0.027170</td>\n","      <td>0.076114</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.152061</td>\n","      <td>-0.014739</td>\n","      <td>-0.080112</td>\n","      <td>-0.009516</td>\n","      <td>0.024130</td>\n","      <td>0.153802</td>\n","      <td>-0.048061</td>\n","      <td>-0.119888</td>\n","      <td>0.059234</td>\n","      <td>0.060882</td>\n","      <td>0.004244</td>\n","      <td>-0.166000</td>\n","      <td>0.045002</td>\n","      <td>0.057566</td>\n","      <td>-0.022081</td>\n","      <td>0.108929</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.014707</td>\n","      <td>-0.011257</td>\n","      <td>0.073692</td>\n","      <td>0.054763</td>\n","      <td>-0.050547</td>\n","      <td>-0.020599</td>\n","      <td>0.027146</td>\n","      <td>-0.067012</td>\n","      <td>0.106593</td>\n","      <td>-0.020921</td>\n","      <td>0.106658</td>\n","      <td>-0.092025</td>\n","      <td>0.024436</td>\n","      <td>0.086183</td>\n","      <td>0.029232</td>\n","      <td>0.016287</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.112812</td>\n","      <td>-0.001395</td>\n","      <td>-0.011572</td>\n","      <td>-0.032638</td>\n","      <td>-0.080440</td>\n","      <td>-0.057321</td>\n","      <td>0.064595</td>\n","      <td>-0.020880</td>\n","      <td>-0.048939</td>\n","      <td>0.068486</td>\n","      <td>-0.031359</td>\n","      <td>-0.044577</td>\n","      <td>-0.002381</td>\n","      <td>0.025505</td>\n","      <td>-0.033164</td>\n","      <td>-0.105266</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>233301</th>\n","      <td>-0.014977</td>\n","      <td>-0.081258</td>\n","      <td>-0.134683</td>\n","      <td>0.027895</td>\n","      <td>0.065370</td>\n","      <td>-0.150696</td>\n","      <td>-0.111557</td>\n","      <td>0.068990</td>\n","      <td>0.023886</td>\n","      <td>-0.130328</td>\n","      <td>0.108049</td>\n","      <td>0.113518</td>\n","      <td>0.083626</td>\n","      <td>-0.134038</td>\n","      <td>-0.002495</td>\n","      <td>-0.016603</td>\n","    </tr>\n","    <tr>\n","      <th>233302</th>\n","      <td>0.026693</td>\n","      <td>-0.047697</td>\n","      <td>0.010914</td>\n","      <td>0.066091</td>\n","      <td>0.023919</td>\n","      <td>-0.017845</td>\n","      <td>-0.013980</td>\n","      <td>-0.010845</td>\n","      <td>0.030093</td>\n","      <td>-0.025450</td>\n","      <td>0.082910</td>\n","      <td>-0.043803</td>\n","      <td>0.015785</td>\n","      <td>0.040697</td>\n","      <td>-0.066637</td>\n","      <td>-0.033264</td>\n","    </tr>\n","    <tr>\n","      <th>233303</th>\n","      <td>0.049292</td>\n","      <td>0.062408</td>\n","      <td>0.137864</td>\n","      <td>-0.134142</td>\n","      <td>-0.072878</td>\n","      <td>0.031165</td>\n","      <td>-0.029502</td>\n","      <td>0.173918</td>\n","      <td>-0.104943</td>\n","      <td>0.029938</td>\n","      <td>-0.138595</td>\n","      <td>-0.000103</td>\n","      <td>-0.007854</td>\n","      <td>0.026256</td>\n","      <td>-0.072040</td>\n","      <td>0.149764</td>\n","    </tr>\n","    <tr>\n","      <th>233304</th>\n","      <td>0.106140</td>\n","      <td>-0.062923</td>\n","      <td>0.147306</td>\n","      <td>0.033648</td>\n","      <td>0.101269</td>\n","      <td>-0.099624</td>\n","      <td>0.099939</td>\n","      <td>0.091838</td>\n","      <td>-0.026377</td>\n","      <td>0.046507</td>\n","      <td>0.088269</td>\n","      <td>0.078541</td>\n","      <td>-0.089107</td>\n","      <td>0.001519</td>\n","      <td>-0.048838</td>\n","      <td>0.147942</td>\n","    </tr>\n","    <tr>\n","      <th>233305</th>\n","      <td>0.105796</td>\n","      <td>-0.059025</td>\n","      <td>0.123408</td>\n","      <td>0.026644</td>\n","      <td>0.017119</td>\n","      <td>0.141981</td>\n","      <td>-0.020873</td>\n","      <td>-0.007717</td>\n","      <td>0.063478</td>\n","      <td>-0.023488</td>\n","      <td>-0.121385</td>\n","      <td>0.044442</td>\n","      <td>-0.048307</td>\n","      <td>0.014245</td>\n","      <td>-0.013478</td>\n","      <td>0.167235</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>233306 rows × 16 columns</p>\n","</div>"],"text/plain":["        Feature0  Feature1  Feature2  Feature3  Feature4  Feature5  Feature6  \\\n","0       0.090378 -0.134799  0.083900  0.046534  0.077417 -0.004537 -0.018561   \n","1       0.059437 -0.084740  0.067107 -0.009036 -0.031482  0.050057  0.125847   \n","2       0.152061 -0.014739 -0.080112 -0.009516  0.024130  0.153802 -0.048061   \n","3      -0.014707 -0.011257  0.073692  0.054763 -0.050547 -0.020599  0.027146   \n","4       0.112812 -0.001395 -0.011572 -0.032638 -0.080440 -0.057321  0.064595   \n","...          ...       ...       ...       ...       ...       ...       ...   \n","233301 -0.014977 -0.081258 -0.134683  0.027895  0.065370 -0.150696 -0.111557   \n","233302  0.026693 -0.047697  0.010914  0.066091  0.023919 -0.017845 -0.013980   \n","233303  0.049292  0.062408  0.137864 -0.134142 -0.072878  0.031165 -0.029502   \n","233304  0.106140 -0.062923  0.147306  0.033648  0.101269 -0.099624  0.099939   \n","233305  0.105796 -0.059025  0.123408  0.026644  0.017119  0.141981 -0.020873   \n","\n","        Feature7  Feature8  Feature9  Feature10  Feature11  Feature12  \\\n","0       0.079236 -0.024561  0.027359  -0.188823  -0.080762   0.050271   \n","1       0.066517 -0.053798 -0.021671   0.064212   0.204660  -0.004188   \n","2      -0.119888  0.059234  0.060882   0.004244  -0.166000   0.045002   \n","3      -0.067012  0.106593 -0.020921   0.106658  -0.092025   0.024436   \n","4      -0.020880 -0.048939  0.068486  -0.031359  -0.044577  -0.002381   \n","...          ...       ...       ...        ...        ...        ...   \n","233301  0.068990  0.023886 -0.130328   0.108049   0.113518   0.083626   \n","233302 -0.010845  0.030093 -0.025450   0.082910  -0.043803   0.015785   \n","233303  0.173918 -0.104943  0.029938  -0.138595  -0.000103  -0.007854   \n","233304  0.091838 -0.026377  0.046507   0.088269   0.078541  -0.089107   \n","233305 -0.007717  0.063478 -0.023488  -0.121385   0.044442  -0.048307   \n","\n","        Feature13  Feature14  Feature15  \n","0       -0.066013   0.058894  -0.007689  \n","1        0.007914   0.027170   0.076114  \n","2        0.057566  -0.022081   0.108929  \n","3        0.086183   0.029232   0.016287  \n","4        0.025505  -0.033164  -0.105266  \n","...           ...        ...        ...  \n","233301  -0.134038  -0.002495  -0.016603  \n","233302   0.040697  -0.066637  -0.033264  \n","233303   0.026256  -0.072040   0.149764  \n","233304   0.001519  -0.048838   0.147942  \n","233305   0.014245  -0.013478   0.167235  \n","\n","[233306 rows x 16 columns]"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["X"]},{"cell_type":"markdown","id":"b0d4a8e3-3ae8-40e6-b6d8-c3cfe88e52c9","metadata":{},"source":["and split X and y into training and testing dataset:\n"]},{"cell_type":"code","execution_count":28,"id":"33eb8796-aac1-4e5f-bb69-8caf101051ef","metadata":{},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rs)"]},{"cell_type":"code","execution_count":29,"id":"b7f6886c-21a4-4733-98fc-be3110b4aa0b","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Input data shape: (233306, 16), Output data shape: (233306,)\n"]}],"source":["print(f\"Input data shape: {X.shape}, Output data shape: {y.shape}\")"]},{"cell_type":"markdown","id":"daca16d3-dae3-40af-aa42-7e6225937ffb","metadata":{},"source":["## TASK: Perform classification tasks on the interaction dataset\n"]},{"cell_type":"markdown","id":"ec03abab-c373-47d6-909d-08e59e3b7c2d","metadata":{},"source":["Now our input data `X` and output label `y` is ready, let's build classification models to map `X` to `y`\n"]},{"cell_type":"markdown","id":"a7a3ee6e-f2e2-436c-b8ea-b00c6d56cb42","metadata":{},"source":["You may use `sklearn` to train and evaluate various regression models.\n"]},{"cell_type":"markdown","id":"65c2d09b-7a09-4994-81d4-30475d4fbffc","metadata":{},"source":["_TODO: Define classification models such as Logistic Regression, Tree models, SVM, Bagging, and Boosting models_\n"]},{"cell_type":"code","execution_count":32,"id":"68750421-aeec-46bc-b099-5dfc1c94164f","metadata":{},"outputs":[{"data":{"text/plain":["1    0.952954\n","0    0.047046\n","Name: proportion, dtype: float64"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["### WRITE YOUR CODE HERE\n","pd.Series(y).value_counts(normalize=True)"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["from sklearn.metrics import classification_report\n","c_weight ={}\n","# We have two weights 1 is 0.95 and 0.04 respectively\n","c_weight[0]=0.952954\n","c_weight[1]=0.047046"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["model_logReg = LogisticRegression(penalty='l2',random_state=rs, max_iter=1000,class_weight=c_weight)"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"]},{"data":{"text/plain":["array([[0.36318011, 0.63681989],\n","       [0.46788898, 0.53211102],\n","       [0.50884711, 0.49115289],\n","       ...,\n","       [0.3790562 , 0.6209438 ],\n","       [0.37612317, 0.62387683],\n","       [0.35201844, 0.64798156]])"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["threshhold=0.5\n","model_logReg.fit(X_train,y_train)\n","predicted_probability = model_logReg.predict_proba(X_test)\n","predicted_probability"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"data":{"text/plain":["array([0.63681989, 0.53211102, 0.49115289, ..., 0.6209438 , 0.62387683,\n","       0.64798156])"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["predicted_probability[:,1]"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["yp_lr = (predicted_probability[:,1] >= threshhold).astype('int')"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.65      0.07      0.12     20638\n","           1       0.57      0.97      0.72     26024\n","\n","    accuracy                           0.57     46662\n","   macro avg       0.61      0.52      0.42     46662\n","weighted avg       0.60      0.57      0.45     46662\n","\n"]}],"source":["print(classification_report(yp_lr,y_test))"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["# Bulding SVM model\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.svm import SVC\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["estimators =[('SVM',SVC(random_state=42)),('KNN',KNeighborsClassifier()),('dt',DecisionTreeClassifier())]"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["clf=StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"]}],"source":["clf.fit(X_train,y_train)\n","preds_clf=clf.predict(X_test)"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.84      0.96      0.90      1871\n","           1       1.00      0.99      1.00     44791\n","\n","    accuracy                           0.99     46662\n","   macro avg       0.92      0.97      0.95     46662\n","weighted avg       0.99      0.99      0.99     46662\n","\n"]}],"source":["print(classification_report(preds_clf,y_test))"]},{"cell_type":"markdown","id":"a8005933-a03c-4c0d-8dad-a12b5b9c85f2","metadata":{},"source":["<details>\n","    <summary>Click here for Hints </summary>\n","    \n","For Example: you can call `RandomForestClassifier()` to define your model, don't forget to specify `max_depth= ..`  and `random_state=rs` in the parameters.\n"]},{"cell_type":"markdown","id":"8b4cff7e-1d67-4003-8b91-447edb4e8648","metadata":{},"source":["_TODO: Train your classification models with training data_\n"]},{"cell_type":"code","execution_count":49,"id":"27554d84-bacc-4551-ac3d-c7a63632fc43","metadata":{},"outputs":[],"source":["### WRITE YOUR CODE HERE\n","### You may need to tune the hyperparameters of the models\n","import pickle\n","pickle.dump(clf,open('stackingclassifier.sav','wb'))"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["load_model = pickle.load(open('stackingclassifier.sav','rb'))"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n","/home/mfarooq28/Documents/first_app/.conda/lib/python3.9/site-packages/sklearn/utils/validation.py:623: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"]}],"source":["preds_clf=load_model.predict(X_test)"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE 0.09464691575011283\n"]}],"source":["import numpy as np\n","from sklearn.metrics import mean_squared_error\n","print('RMSE', np.sqrt(mean_squared_error(preds_clf,y_test)))"]},{"cell_type":"markdown","id":"1a9530b6-2df8-4afd-a3b3-196cfec4d006","metadata":{},"source":["<details>\n","    <summary>Click here for Hints</summary>\n","    \n","You can call `model.fit()` method with `X_train, y_train` parameters.\n"]},{"cell_type":"markdown","id":"7becf36f-74e9-43c8-b1c0-4bc152c2962b","metadata":{},"source":["_TODO: Evaluate your classification models_\n"]},{"cell_type":"code","execution_count":null,"id":"a4119cba-01d6-44b6-90e6-6f8118e44328","metadata":{},"outputs":[],"source":["### WRITE YOUR CODE HERE\n","\n","### The main evaluation metrics could be accuracy, recall, precision, F score, and AUC.\n"]},{"cell_type":"markdown","id":"23d7e867-0f89-4249-bdce-b82eccba8ca3","metadata":{},"source":["<details>\n","    <summary>Click here for Hints</summary>\n","    \n","You can call `model.predict()` method with `X_test` parameter to get model predictions. Then use `accuracy_score()` with `y_test, your_predictions` parameters to calculate the accuracy value. \n","* You can use `precision_recall_fscore_support` command  with `y_test, your_predictions, average='binary'` parameters get recall, precision and F score.\n","    \n"]},{"cell_type":"markdown","id":"59a14447-c245-40d4-8a95-62237b8bd592","metadata":{},"source":["### Summary\n"]},{"cell_type":"markdown","id":"3c9515ba-573d-4466-b990-ce3c2343e8ef","metadata":{},"source":["In this lab, you have built and evaluated various classification models to predict categorical course rating modes using the embedding feature vectors extracted from neural networks.\n"]},{"cell_type":"markdown","id":"ff0121ac-b3d9-489c-91b8-513535322891","metadata":{},"source":["## Authors\n"]},{"cell_type":"markdown","id":"46cfc1a1-9b3d-4e90-890f-f0d6ab558a6e","metadata":{},"source":["[Yan Luo](https://www.linkedin.com/in/yan-luo-96288783/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML321ENSkillsNetwork817-2022-01-01)\n"]},{"cell_type":"markdown","id":"76da3906-0434-45c5-b64d-630139216c65","metadata":{},"source":["### Other Contributors\n"]},{"cell_type":"markdown","id":"09d59819-84ce-4c39-94fd-ad11094b4dce","metadata":{},"source":["## Change Log\n"]},{"cell_type":"markdown","id":"3d55ffb4-0381-4e06-b622-ca12f367b586","metadata":{},"source":["|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n","|-|-|-|-|\n","|2021-10-25|1.0|Yan|Created the initial version|\n"]},{"cell_type":"markdown","id":"fac70bb5-a447-47c0-8242-c5b19d4efcf2","metadata":{},"source":["Copyright © 2021 IBM Corporation. All rights reserved.\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":4}
